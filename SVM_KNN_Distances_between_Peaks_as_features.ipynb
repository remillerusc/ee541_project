{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM and KKN with Distances Between Peaks as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load major and minor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minor_251.wav not found. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zm/3v1wdprn37z_zbm8f6vf0j0r0000gn/T/ipykernel_10927/112073577.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, audio_data = wavfile.read(f\"Audio_Files/Major/Major_{num}.wav\")\n"
     ]
    }
   ],
   "source": [
    "data_major = []\n",
    "data_minor = []\n",
    "sample_rates = []\n",
    "data_length = []\n",
    "for num in range(502):\n",
    "    sample_rate, audio_data = wavfile.read(f\"Audio_Files/Major/Major_{num}.wav\")\n",
    "    data_major.append(audio_data)\n",
    "    sample_rates.append(sample_rate)\n",
    "    data_length.append(len(audio_data))\n",
    "\n",
    "for num in range(358):\n",
    "    try:\n",
    "        sample_rate, audio_data = wavfile.read(f\"Audio_Files/Minor/Minor_{num}.wav\")\n",
    "    except:\n",
    "        print(f\"Minor_{num}.wav not found. Skipping...\")\n",
    "        continue\n",
    "    data_minor.append(audio_data)\n",
    "    sample_rates.append(sample_rate)\n",
    "    data_length.append(len(audio_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine FFT Parameters (FFT size, Sampling Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101429"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The max data length amoung all data\n",
    "max(data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_size = 2**17\n",
    "fft_size\n",
    "# Use this fft size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sample_rates == sample_rates[0] * np.ones((1,len(sample_rates)))) == len(sample_rates)\n",
    "# Sampling rate for all audio file is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = sample_rates[0]\n",
    "sample_rate    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.336456298828125"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_resoluion = sample_rate/fft_size\n",
    "fft_resoluion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_bins = np.fft.rfftfreq(n=fft_size,d=1/sample_rate)\n",
    "num_peaks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_frequencies = [\n",
    "    27.5000, 29.1352, 30.8677, 32.7032, 34.6478, 36.7081, 38.8909, 41.2034, 43.6535,\n",
    "    46.2493, 48.9994, 51.9131, 55.0000, 58.2705, 61.7354, 65.4064, 69.2957, 73.4162,\n",
    "    77.7817, 82.4069, 87.3071, 92.4986, 97.9989, 103.826, 110.000, 116.541, 123.471,\n",
    "    130.813, 138.591, 146.832, 155.563, 164.814, 174.614, 184.997, 195.998, 207.652,\n",
    "    220.000, 233.082, 246.942, 261.626, 277.183, 293.665, 311.127, 329.628, 349.228,\n",
    "    369.994, 391.995, 415.305, 440.000, 466.164, 493.883, 523.251, 554.365, 587.330,\n",
    "    622.254, 659.255, 698.456, 739.989, 783.991, 830.609, 880.000, 932.328, 987.767,\n",
    "    1046.50, 1108.73, 1174.66, 1244.51, 1318.51, 1396.91, 1479.98, 1567.98, 1661.22,\n",
    "    1760.00, 1864.66, 1975.53, 2093.00, 2217.46, 2349.32, 2489.02, 2637.02, 2793.83,\n",
    "    2959.96, 3135.96, 3322.44, 3520.00, 3729.31, 3951.07, 4186.01\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_ranges = []\n",
    "for i in range(len(note_frequencies)):\n",
    "    if i == 0: \n",
    "        low = 0\n",
    "    else:\n",
    "        low = (note_frequencies[i - 1] + note_frequencies[i]) / 2\n",
    "    if i == len(note_frequencies) - 1:  \n",
    "        high = np.inf\n",
    "    else:\n",
    "        high = (note_frequencies[i] + note_frequencies[i + 1]) / 2\n",
    "    note_ranges.append((low, high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_frequencies_to_notes(frequencies):\n",
    "    note_matches = []\n",
    "    for freq in frequencies:\n",
    "        matched = False\n",
    "        for i, (low, high) in enumerate(note_ranges):\n",
    "            if low <= freq < high:\n",
    "                note_matches.append(i) \n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            note_matches.append(None)  \n",
    "    return note_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zm/3v1wdprn37z_zbm8f6vf0j0r0000gn/T/ipykernel_10927/1280290111.py:7: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unqie_note_matches = pd.unique(match_frequencies_to_notes(sorted_freq))\n"
     ]
    }
   ],
   "source": [
    "features_label = []\n",
    "for data in data_major:\n",
    "    freq_data = np.abs(np.fft.rfft(data, n=fft_size))\n",
    "    peak_indices, _ = find_peaks(freq_data)\n",
    "    sorted_peak_indices = peak_indices[np.argsort(freq_data[peak_indices])[::-1]]\n",
    "    sorted_freq = frequency_bins[sorted_peak_indices]\n",
    "    unqie_note_matches = pd.unique(match_frequencies_to_notes(sorted_freq))\n",
    "    unqie_note_matches = unqie_note_matches[unqie_note_matches != 0]\n",
    "    unqie_note_matches = unqie_note_matches[:num_peaks]\n",
    "    unqie_note_matches = np.sort(unqie_note_matches)\n",
    "    notes_with_label = np.append(unqie_note_matches,1)\n",
    "    features_label.append(notes_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zm/3v1wdprn37z_zbm8f6vf0j0r0000gn/T/ipykernel_10927/400093191.py:6: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unqie_note_matches = pd.unique(match_frequencies_to_notes(sorted_freq))\n"
     ]
    }
   ],
   "source": [
    "for data in data_minor:\n",
    "    freq_data = np.abs(np.fft.rfft(data, n=fft_size))\n",
    "    peak_indices, _ = find_peaks(freq_data)\n",
    "    sorted_peak_indices = peak_indices[np.argsort(freq_data[peak_indices])[::-1]]\n",
    "    sorted_freq = frequency_bins[sorted_peak_indices]\n",
    "    unqie_note_matches = pd.unique(match_frequencies_to_notes(sorted_freq))\n",
    "    unqie_note_matches = unqie_note_matches[unqie_note_matches != 0]\n",
    "    unqie_note_matches = unqie_note_matches[:num_peaks]\n",
    "    unqie_note_matches = np.sort(unqie_note_matches)\n",
    "    notes_with_label = np.append(unqie_note_matches,0)\n",
    "    features_label.append(notes_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_label_shuffled = shuffle(features_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features_label_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data_preprocessed_v2.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features_label_shuffled)[:, :-1]\n",
    "for i in range(7):\n",
    "    X[:,i] = X[:,i] - X[:,i+1] # Calcuate the distances between notes\n",
    "X = X[:,:6] # Use first 6 distances => 6 features\n",
    "y = np.array(features_label_shuffled)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 2, 'gamma': 2.0, 'kernel': 'rbf'}\n",
      "Best Cross-Validation Score:  0.8529567333121759\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1,2,3,4,5,10,15,20, 100],\n",
    "    'gamma': np.linspace(2,6,100),\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "grid = GridSearchCV(SVC(class_weight='balanced',random_state=42), param_grid, refit=True, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid.best_params_)\n",
    "print(\"Best Cross-Validation Score: \", grid.best_score_)\n",
    "\n",
    "best_svm = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9011627906976745\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n",
      "Best Cross-Validation Accuracy: 0.8646355654289642\n",
      "Test Accuracy: 0.872093023255814\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [1, 2,3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'p': [1, 2]  #(1 = Manhattan, 2 = Euclidean)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
